#  Projeto - Conhecendo o AWS SageMaker para tarefas de Machine Learning

<h1>
    <img src="https://i.ibb.co/w6NGdV6/Certificado.jpg" alt="SQL Server e XML-Persistindo XML de maneira eficiente" border="0">
</h1>
<br>
Reposit√≥rio de c√≥digos da plataforma de Projetos PRO da <a href="https://web.digitalinnovation.one/labs">***Digital Innovation One***</a> sobre AWS Sagemaker
<br>
AWS Sagemaker √© um servi√ßo totalmente gerenciado da AWS, que pode nos ajudar a preparar, criar, treinar e implantar modelos de Machine Learning (ML) de alta qualidade rapidamente. Para isso, o expert apresenta algumas das features dispon√≠veis nessa ferramenta, explorando na pr√°tica um pouco do seu potencial.
<br>
<h2>
    <img src="https://i.ibb.co/7Qd6fn9/1.png" alt="AWS Sagemaker" border="0">
</h2>
<br>
<h2>
    <img src="https://i.ibb.co/jbPWQCV/3.png" alt="AWS Sagemaker" border="0">
</h2>

# Passo a Passo

<h2>
      <img src="https://i.ibb.co/rvxPmz9/4.png" alt="AWS Sagemaker" border="0">
</h2>

## Passo 1 - Crie uma inst√¢ncia de notebook Amazon SageMaker para prepara√ß√£o de dados
Nesta etapa, cria-se a inst√¢ncia do notebook que usa para baixar e processar seus dados. Como parte do processo de cria√ß√£o, voc√™ tamb√©m cria uma fun√ß√£o de gerenciamento de identidade e acesso (IAM) que permite ao Amazon SageMaker acessar dados no Amazon S3.

- Fa√ßa login no console do Amazon SageMaker e, no canto superior direito, selecione sua regi√£o AWS preferida. Este tutorial usa a regi√£o US West (Oregon).
- No painel de navega√ß√£o esquerdo, escolha ```Notebook instances```, e ```Create notebook instance```.
- Na p√°gina ```Create notebook instance```, na caixa ```Notebook instance setting```, preencha os seguintes campos:
  - Para ```Notebook instance name```, digite ```SageMaker-DIO-Live```.
  - Para ```Notebook instance type```, escolha ```ml.t2.medium```.
  - Para ```Elastic inference```, mantenha a sele√ß√£o padr√£o de ```none```.
- Na se√ß√£o ```Permissions and encryption```, para  ```IAM role```, escolha ```Create a new role``` e, na caixa de di√°logo ```Create an IAM role```, selecione ```Any S3 bucket``` e escolha ```Create role```.
Observa√ß√£o: se voc√™ j√° tem um bucket que gostaria de usar, escolha ```Specific S3 buckets``` e especifique o nome do bucket.
- Amazon SageMaker creates the ```AmazonSageMaker-ExecutionRole-***``` role.
-  Mantenha as configura√ß√µes padr√£o para o restante das op√ß√µes e selecione ```Create notebook instance```.
Em ```Notebook instances section```, a nova inst√¢ncia do Notebook ser√° mostrada no status de ```Pending```. O Notebook estar√° dispon√≠vel quando o status mudar para  ``` InService```. 

## Passo 2 - Preparar os dados
Nesta etapa, voc√™ usa sua inst√¢ncia de notebook do Amazon SageMaker para pr√©-processar os dados de que precisa para treinar seu modelo de aprendizado de m√°quina e, em seguida, fazer upload dos dados para o Amazon S3.

 - Depois da sua inst√¢ncia do Notebook mudar o status para ```InService``` selecion ```Open Jupyter```
 - Em ```Jupyter``` selecione ```New``` e escolha ```conda_python3```
 - Em uma nova c√©lula de c√≥digo no Jupyter Notebook, copie e cole o seguinte c√≥digo e selecione ```Run```
 ```
 # import libraries
import boto3, re, sys, math, json, os, sagemaker, urllib.request
from sagemaker import get_execution_role
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import Image
from IPython.display import display
from time import gmtime, strftime
from sagemaker.predictor import csv_serializer

# Define IAM role
role = get_execution_role()
prefix = 'sagemaker/DEMO-xgboost-dm'
my_region = boto3.session.Session().region_name # set the region of the instance

# this line automatically looks for the XGBoost image URI and builds an XGBoost container.
xgboost_container = sagemaker.image_uris.retrieve("xgboost", my_region, "latest")

print("Success - the MySageMakerInstance is in the " + my_region + " region. You will use the " + xgboost_container + " container for your SageMaker endpoint.")
 ```
- Crie o bucket S3 para armazenar eus dados. Copie e cole o c√≥digo a seguir em uma nova c√©lula de c√≥digo, altere o nome do bucket e selecione ```Run```
```
bucket_name = 'your-s3-bucket-name' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET
s3 = boto3.resource('s3')
try:
    if  my_region == 'us-east-1':
      s3.create_bucket(Bucket=bucket_name)
    else: 
      s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={ 'LocationConstraint': my_region })
    print('S3 bucket created successfully')
except Exception as e:
    print('S3 error: ',e)
 ```
- Fa√ßa o donwload dos dados para a sua inst√¢ncia do SageMaker e carregue os dados em um dataframe. Copie e cole o seguinte c√≥digo em uma nova c√©lula de c√≥digo e clique em ```Run```
```
try:
  urllib.request.urlretrieve ("https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv", "bank_clean.csv")
  print('Success: downloaded bank_clean.csv.')
except Exception as e:
  print('Data load error: ',e)

try:
  model_data = pd.read_csv('./bank_clean.csv',index_col=0)
  print('Success: Data loaded into dataframe.')
except Exception as e:
    print('Data load error: ',e)
 ```
 - Misture e divida os dados em dados de treinamento e dados de teste. Copie e cole o c√≥digo a seguir na pr√≥xima c√©lula de c√≥digo e escolha Executar. Os dados de treinamento (70% dos clientes) s√£o usados durante o loop de treinamento do modelo. Use a otimiza√ß√£o baseada em gradiente para refinar iterativamente os par√¢metros do modelo. A otimiza√ß√£o baseada em gradiente √© uma maneira de encontrar os valores dos par√¢metros do modelo que minimizam o erro do modelo, usando o gradiente da fun√ß√£o de perda do modelo. Os dados de teste (restantes 30% dos clientes) s√£o usados para avaliar o desempenho do modelo e medir qu√£o bem o modelo treinado generaliza para dados invis√≠veis.

 ```
train_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data))])
print(train_data.shape, test_data.shape)
 ```
 ## Passo 3 - Treinar o modelo de ML
 Nesta etapa, voc√™ usa seu conjunto de dados de treinamento para treinar seu modelo de aprendizado de m√°quina.
 
 - Em uma nova c√©lula de c√≥digo em seu Notebook Jupyter, copie e cole o c√≥digo a seguir e escolha Executar. Este c√≥digo reformata o cabe√ßalho e a primeira coluna dos dados de treinamento e, em seguida, carrega os dados do bucket S3. Esta etapa √© necess√°ria para usar o algoritmo XGBoost pr√©-constru√≠do do Amazon SageMaker.

```
pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('train.csv', index=False, header=False)
boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')
s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')
```

- Configure a sess√£o do Amazon SageMaker, crie uma inst√¢ncia do modelo XGBoost (um estimador) e defina os hiperpar√¢metros do modelo. Copie e cole o seguinte c√≥digo na pr√≥xima c√©lula de c√≥digo e escolha ```Run```
```
sess = sagemaker.Session()
xgb = sagemaker.estimator.Estimator(xgboost_container,role, instance_count=1, instance_type='ml.m4.xlarge',output_path='s3://{}/{}/output'.format(bucket_name, prefix),sagemaker_session=sess)
xgb.set_hyperparameters(max_depth=5,eta=0.2,gamma=4,min_child_weight=6,subsample=0.8,silent=0,objective='binary:logistic',num_round=100)
```
- Comece o trabalho de treinamento. Copie e cole o c√≥digo a seguir na pr√≥xima c√©lula de c√≥digo e escolha Executar. Este c√≥digo treina o modelo usando a otimiza√ß√£o de gradiente em uma inst√¢ncia ml.m4.xlarge. Depois de alguns minutos, voc√™ deve ver os registros de treinamento sendo gerados em seu Notebook Jupyter.

```
xgb.fit({'train': s3_input_train})
```

## Passo 4 - Publicar o modelo de ML
Nesta etapa, voc√™ implanta o modelo treinado em um endpoint, reformata e carrega os dados CSV e, em seguida, executa o modelo para criar previs√µes.

- Em uma nova c√©lula de c√≥digo do Notebook Jupyter, copie e cole o c√≥digo a seguir e escolha ```Run```. Este c√≥digo implanta o modelo em um servidor e cria um endpoint SageMaker para acessi. Esta etapa pode levar alguns minutos para ser conclu√≠da.
```
xgb_predictor = xgb.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')
```
- Para realizar a predi√ß√£o dos clientes que ir√£o aderir ao produto do banco ou n√£o na amostra de testes, copie e cole o seguinte c√≥digo em uma nova c√©lula ```Run```
```
from sagemaker.serializers import CSVSerializer

test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #load the data into an array
xgb_predictor.serializer = CSVSerializer() # set the serializer type
predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!
predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array
print(predictions_array.shape)
```

## Passo 5 - Avaliar a performance do modelo treinado

Em uma nova c√©lula do Notebook Jupyter, copie e cole o seguinte c√≥digo e selecione ```Run```. Este c√≥digo compara os valores atuais com os preditos em uma tabela chamada *Matriz de Confus√£o*. Baseado na predi√ß√£o, pode-se concluir que um cliente ir√° se inscrever para um certificado de dep√≥sito com acur√°cia de 90% para os clientes dos dados de teste, uma precis√£o de 65% para os que ir√£o se inscrever e 90% para os que n√£o ir√£o se inscrever.

```
cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])
tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100
print("\n{0:<20}{1:<4.1f}%\n".format("Overall Classification Rate: ", p))
print("{0:<15}{1:<15}{2:>8}".format("Predicted", "No Purchase", "Purchase"))
print("Observed")
print("{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})".format("No Purchase", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))
print("{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \n".format("Purchase", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))
```

## Passo 6 - Limpar os recursos
Neste passo voc√™ ir√° limpar o ambiente com os recursos
Importante: Encerrar recursos que n√£o est√£o sendo usados ativamente reduz custos e √© uma pr√°tica recomendada. N√£o encerrar seus recursos resultar√° em cobran√ßas em sua conta.
 - Deletar o seu endpoind: No seu Notebook Jupyter, copie e cole o seguinte c√≥digo e escolhe ```Run```
 ```
 xgb_predictor.delete_endpoint(delete_endpoint_config=True)
 ```
 - Deletar os artefatos de treino e o bucket S3: No seu Notebook Jupyter, copie e cole o seguinte c√≥digo e selecione ```Run```
 ```
bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)
bucket_to_delete.objects.all().delete()
 ```
- Excluir o seu SageMaker Notebook: Parar e excluir o seu SageMaker Notebook
  - Abrir o ```SageMaker Console```
  - Em ```Notebook``` escolha ```Notebook instances```
  - Selecione a inst√¢ncia do Notebook criada, selecione ```Actions``` e ```Stop```. Este procedimento pode levar alguns minutos, e quando o status mudar para ```Stopped```, v√° para o passo seguinte
  - Selecione ```Actions``` e depois ```Delete```
  - Selecione ```Delete```

## Me siga nas redes sociais

üßëüèº‚Äçüíªüë©üèº‚Äçüíª https://linktr.ee/ygtecnologia 
<br>
<br> 
Investir em conhecimento rende sempre os melhores juros. Benjamim Franklin
<br>
<br> 
üôè Ora√ß√£o ! Foco ! A√ß√£o ! Yeshua Hamashia